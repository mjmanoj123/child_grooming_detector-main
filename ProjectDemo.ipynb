{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectDemo.ipynb",
      "provenance": [],
      "mount_file_id": "1Xt1VqugvY5ZtN7Jkl-K2sno0T0ejOvX1",
      "authorship_tag": "ABX9TyMvQFAUzUTr/XUIcHTA6Rrf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavinciB/child_grooming_detector/blob/main/ProjectDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqJO9UUheYb8",
        "outputId": "3d4d54ee-3b5f-46a3-a3b9-52bda5406770"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJee5ZmDuuip"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import heapq\n",
        "import operator\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
        "from sklearn.svm import LinearSVC\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3AvMn9Vm2-Y"
      },
      "source": [
        "def get_labels_dict(data_path):\n",
        "    labels_dict = {}\n",
        "    with open(data_path + 'sci_labels.csv', 'r') as f:\n",
        "        file = csv.reader(f)\n",
        "        for row in file:\n",
        "            labels_dict[row[0]] = row[1]\n",
        "    return labels_dict\n",
        "\n",
        "def get_features_labels(root, labels_dict):\n",
        "    corpus = []\n",
        "    labels = []\n",
        "    for conversation in root:\n",
        "        string = \" \"\n",
        "        for message in conversation:\n",
        "            text = message.find('text').text\n",
        "            if text is not None:\n",
        "                string = string + \"\\r\\n\" + text\n",
        "        corpus.append(string)\n",
        "        labels.append(int(labels_dict[conversation.get('id')]))\n",
        "    return corpus, labels\n",
        "\n",
        "def get_conversation_id(root):\n",
        "  conversation_id = []\n",
        "  for conversation in root:\n",
        "    conversation_id.append(conversation.get('id'))\n",
        "  return conversation_id\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/online-grooming-detector-master/data/svm_training_data/'\n",
        "training_xml = ET.parse(train_data_path + 'training_data.xml')\n",
        "train_root = training_xml.getroot()\n",
        "test_data_path = '/content/drive/MyDrive/online-grooming-detector-master/data/svm_test_data/'\n",
        "test_data_src = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-test-corpus-2012-05-21/'\n",
        "test_xml = ET.parse(test_data_src + 'pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
        "test_root = test_xml.getroot()\n",
        "train_corpus, train_labels = get_features_labels(train_root, get_labels_dict(train_data_path))\n",
        "test_corpus, test_labels = get_features_labels(test_root, get_labels_dict(test_data_path))\n",
        "test_conversations = get_conversation_id(test_root)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_corpus)\n",
        "X_test = vectorizer.transform(test_corpus)\n",
        "X_test = scipy.sparse.csr_matrix(X_test)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "filename = '/content/drive/MyDrive/online-grooming-detector-master/models/GAI_SVM.sav'\n",
        "loaded_model_GAI = pickle.load(open(filename, 'rb'))\n",
        "pred_y = loaded_model_GAI.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, pred_y))\n",
        "occurrences = np.count_nonzero(pred_y == 1)\n",
        "print(occurrences)\n",
        "for i in range(250):\n",
        "    print(\"{} {}\".format(test_conversations[i], pred_y[i]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlPb-7PE9-J"
      },
      "source": [
        "demo_list_1 = []\n",
        "for i in range(10000):\n",
        "  if (pred_y[i] == 1) :\n",
        "    for conversation in test_root :\n",
        "      if test_conversations[i] == conversation.get('id') :\n",
        "        count = 0\n",
        "        for message in conversation:\n",
        "          count += 1\n",
        "        if count > 100 :\n",
        "          print(\"{} {}\".format(test_conversations[i], pred_y[i]))\n",
        "          demo_list_1.append(test_conversations[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RzAGiDYhfjI"
      },
      "source": [
        "for Id in demo_list_1 :\n",
        "  for conversation in test_root :\n",
        "    if Id == conversation.get('id') :\n",
        "      count = 0\n",
        "      for message in conversation:\n",
        "              count += 1\n",
        "      if count > 25 :\n",
        "        print(\"*****************************************************************************************\")\n",
        "        for message in conversation:\n",
        "              text = message.find('text').text\n",
        "              print(text)\n",
        "        print(\"*****************************************************************************************\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4DIy7GAoPVe"
      },
      "source": [
        "test_corpus = []\n",
        "test_labels = []\n",
        "pred_y = []\n",
        "def get_susp_conv_dict(data_path):\n",
        "    labels_dict = {}\n",
        "    with open(data_path + 'sci_labels.csv', 'r') as f:\n",
        "        file = csv.reader(f)\n",
        "        for row in file:\n",
        "            labels_dict[row[0]] = row[1]\n",
        "    return labels_dict\n",
        "\n",
        "def get_predators_dict(file): \n",
        "    all_predators = {}\n",
        "    with open(file, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            all_predators[row[0]] = 1\n",
        "    return all_predators\n",
        "            \n",
        "def get_features_labels(root, labels_dict, all_predators):\n",
        "    corpus = []\n",
        "    labels = []\n",
        "    author_list = []\n",
        "    for conversation in root:\n",
        "        if labels_dict[conversation.get('id')] == '0':\n",
        "            continue\n",
        "        author_conv_dict = {}\n",
        "        for message in conversation:\n",
        "            author = message.find('author').text\n",
        "            text = message.find('text').text\n",
        "            if text is not None:\n",
        "                if author not in author_conv_dict:\n",
        "                    author_conv_dict[author] = text\n",
        "                else:\n",
        "                    author_conv_dict[author] += \" \" + text \n",
        "        for author, conv in author_conv_dict.items():\n",
        "            corpus.append(conv)\n",
        "            author_list.append(author)\n",
        "            if author in all_predators:\n",
        "                labels.append(1)\n",
        "            else:\n",
        "                labels.append(-1)\n",
        "    return corpus, labels, author_list\n",
        "\n",
        "\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/online-grooming-detector-master/data/svm_training_data/'\n",
        "training_xml = ET.parse(train_data_path + 'training_data.xml')\n",
        "train_root = training_xml.getroot()\n",
        "\n",
        "test_data_path = '/content/drive/MyDrive/online-grooming-detector-master/data/svm_test_data/'\n",
        "test_data_src = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-test-corpus-2012-05-21/'\n",
        "test_xml = ET.parse(test_data_src + 'pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
        "test_root = test_xml.getroot()\n",
        "\n",
        "pred_train_file_path = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt'\n",
        "pred_test_file_path = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem1.txt'\n",
        "train_corpus, train_labels, train_authors = get_features_labels(train_root, get_susp_conv_dict(train_data_path), get_predators_dict(pred_train_file_path))\n",
        "test_corpus, test_labels, test_authors = get_features_labels(test_root, get_susp_conv_dict(test_data_path), get_predators_dict(pred_test_file_path))\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "X_train = vectorizer.fit_transform(train_corpus)\n",
        "X_test = vectorizer.transform(test_corpus)\n",
        "X_test = scipy.sparse.csr_matrix(X_test)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "filename = '/content/drive/MyDrive/online-grooming-detector-master/models/PI_SVM.sav'\n",
        "loaded_model_PI = pickle.load(open(filename, 'rb'))\n",
        "pred_y = loaded_model_PI.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, pred_y))\n",
        "occurrences = np.count_nonzero(pred_y == 1)\n",
        "print(occurrences)\n",
        "print(\"Suspicious authors are\")\n",
        "for i in range(len(test_authors)//4):\n",
        "    print(\"{} {}\".format(test_authors[i], pred_y[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}