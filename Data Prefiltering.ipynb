{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZEGl6MZG7flqFfFbLnLsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavinciB/child_grooming_detector/blob/main/Data%20Prefiltering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gcBF1oazCUE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNC7Ioy4zGWy"
      },
      "source": [
        "import xml.etree.ElementTree as ET #for parsing the xml file to a tree\n",
        "import datetime\n",
        "#store the path to the folder containing the training data\n",
        "train_data_path = r\"/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-training-corpus-2012-05-01\"\n",
        "#parse the training data xml file\n",
        "training_xml = ET.parse(train_data_path + '/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml')\n",
        "#obtain the root of the tree we created above\n",
        "root = training_xml.getroot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Eth2VozIib"
      },
      "source": [
        "#Adding index attribute to conversations and changing line attributes of messages for ease of pre processing\n",
        "i = 0\n",
        "for conversation in root:\n",
        "  conversation.set('index',i)   #adding an index value to each conversation in the tree\n",
        "  i += 1\n",
        "for conversation in root:\n",
        "  i = 0\n",
        "  for message in conversation:\n",
        "    message.set('line',i) #changing the line value of each messsage in all conversation to be in ordered form\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXWZysFDzLa6"
      },
      "source": [
        "#Before removing single author conversations\n",
        "print(root[1][0][2].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJayDgAdzOb6"
      },
      "source": [
        "#single author \n",
        "conv_2_remove = [] #list to store the conversation id of conversations to be removed\n",
        "authors = [] #list of unique authors in each conversations\n",
        "init_len = len(root) #initial no of conversations\n",
        "\n",
        "for conversation in root:\n",
        "    authors.clear() #clear the authors list before going through each conversation\n",
        "    for message in conversation: #taking individual messages in each conversation\n",
        "        author = message.find('author').text #finding the author of the message\n",
        "        if author not in authors: #if the author is not present in the list\n",
        "            authors.append(author) #append if not\n",
        "\n",
        "    if (len(authors)) <= 1 and conversation.get('id') not in conv_2_remove: #if no of authers less than 1 and conversatio id already not present in conv_2_remove\n",
        "        conv_2_remove.append(conversation.get('id')) #append to the list if not\n",
        "\n",
        "print(str(len(conv_2_remove))+\" out of \"+str(init_len)+\" conversations contain single user\")\n",
        "sing_user = len(conv_2_remove) #no of single user conversations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnLgmHUPzQoR"
      },
      "source": [
        "#Before removing low message count conversations\n",
        "print(root[2][0][2].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TJEsOMVzS_g"
      },
      "source": [
        "#Each user having 5 or less messages\n",
        "for conversation in root: #taaking the conversation on at a time\n",
        "    if conversation.get('id') in conv_2_remove: #check if id of conversation already present in conv_2_remove\n",
        "        continue #skipping if true\n",
        "    authors = {} #python dictionary of authors\n",
        "    for message in conversation: #checking the author of each message in a conversation\n",
        "        author = message.find('author').text\n",
        "        if author in authors: #if present inrement the value\n",
        "            authors[author] = authors[author] + 1\n",
        "        else: #new author store the initial value as 1\n",
        "            authors[author] = 1\n",
        "    remove = True #initialize remove flag as true\n",
        "    for author in authors:\n",
        "        if authors[author] > 5:# checking if any auther have more than 5 messages if no single user have morethan 5 messages the conversation is removed\n",
        "            remove = False #set flag faslse\n",
        "    if remove is True and conversation.get('id') not in conv_2_remove: #check if flag true and conversation id not in list\n",
        "        conv_2_remove.append(conversation.get('id')) #apppend if true\n",
        "low_msg_count = len(conv_2_remove) - sing_user\n",
        "print(str(low_msg_count)+\" out of \"+str(init_len)+\" conversations have low message count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGLOfHuGzW-0"
      },
      "source": [
        "for conversation in root.findall('conversation'): #finds all the children of root having conversation tag ie. the conversations\n",
        "    if conversation.get('id') in conv_2_remove: #if conversation id in list to be removed\n",
        "        root.remove(conversation) #remove the child\n",
        "print(\"The new root has a length of \" + str(len(root)))\n",
        "print(str(init_len - len(root))+\" conversations removed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxnya7A8zZNc"
      },
      "source": [
        "#resetting index attribute to conversations and changing line attributes of messages\n",
        "i = 0\n",
        "for conversation in root:\n",
        "  conversation.set('index',i)   \n",
        "  i += 1\n",
        "for conversation in root:\n",
        "  i = 0\n",
        "  for message in conversation:\n",
        "    message.set('line',i)\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckwNTzA7zbgc"
      },
      "source": [
        "#After removing single author conversations\n",
        "print(root[1][0][2].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsG_wMuizd-k"
      },
      "source": [
        "#Afetr removing low message count conversations\n",
        "print(root[2][0][2].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX-KA7ijzgQv"
      },
      "source": [
        "#Removing sequences of meaningless characters\n",
        "import re #regular expression operators for string matching\n",
        "messages = [] #list of messages\n",
        "count = 0\n",
        "for conversation in root: #take eeach conversation\n",
        "  messages.clear() #clear the message list before each iteration\n",
        "  conv = conversation.get('id') #take the conversatio id \n",
        "  index = conversation.get('index') #take the conversation index for indexing\n",
        "  for message in conversation: #consider each message\n",
        "    text = message.find(\"text\").text #take the text conyent of the message\n",
        "    if text is None or len(text) < 20: #if no text present or length less than 20 skip\n",
        "      continue\n",
        "    match_str = re.findall(\"[\\W_]\", text) #pattern matching expression to find the string of non-word charecters\n",
        "    if len(match_str) / len(text) > 0.6: #if the above string occupies more than 60% of the message it needs to be removed\n",
        "      line = message.get('line') # take the line index from message\n",
        "      messages.append(int(line)) #add the line index to the list\n",
        "    for i in reversed(messages): #iterating from end to top\n",
        "      try: #try statement for unexpected errors due to dataset structure\n",
        "        root[int(index)].remove(root[int(index)][i]) #removing the messages\n",
        "        count += 1\n",
        "      except:\n",
        "        continue #skipping the errors\n",
        "print(str(count)+\" messages has been removed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLbeCVPYzjt3"
      },
      "source": [
        "#Removing index and updating line attributes to str else it gives errror\n",
        "#during converting to xml\n",
        "for i in range(len(root)):\n",
        "  root[i].attrib.pop('index') \n",
        "for conversation in root:\n",
        "  i = 1 #in actual dataset line values started from 1 we chasnged it to start from 0 earlier for easier convenience\n",
        "  for message in conversation:\n",
        "    message.set('line',str(i))\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-p8jobzzmYp"
      },
      "source": [
        "from xml.etree.ElementTree import ElementTree,tostring\n",
        "tree = ElementTree(root)\n",
        "tree.write(open(r'/content/drive/MyDrive/online-grooming-detector-master/data/svm_training_data/training_data.xml', 'wb')) #writing the preprocessed data back\n",
        "print(\"Filtered data written!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}