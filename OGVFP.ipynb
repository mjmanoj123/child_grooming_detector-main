{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuvgIhfT27Ky4BihKfMKU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavinciB/child_grooming_detector/blob/main/OGVFP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YMnpF1_w26M"
      },
      "source": [
        "In this notebook we will be doing some further processing on the prefiltered data for the Victim From Predators disclosure (VFP) stage. It is important to note that only suspicious conversations (conversations that contain predator(s)) are fed into the VFP.\n",
        "\n",
        "There are a few decisions to be made:\n",
        "\n",
        "We have to decide the type of document we feed into the VFP. A document contains messages written by a unique author ideantified by a id.\n",
        "\n",
        "\n",
        "*   We could feed only one document per author. This means that we will be concantenating all messages from a unique author possible from multiple conversations if that author partook in multiple conversations in the dataset. The benefit of this approach is that we could possibly get a better picture of predators if we combine all messages in all conversations together.\n",
        "*   We could feed one document per author per conversation. This means if an author partook in multiple conversations we will have multiple documents for that author. The benefit of this is this would better reflect the type of data in real-world.\n",
        "\n",
        "\n",
        "We could feed one document per author per conversation. This means if an author partook in multiple conversations we will have multiple documents for that author. The benefit of this is this would better reflect the type of data in real-world.\n",
        "\n",
        "We will use the second option for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gI3VIi2wyAh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjKMm6L2x4Na"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_susp_conv_dict(data_path):\n",
        "    labels_dict = {}\n",
        "    with open(data_path + 'sci_labels.csv', 'r') as f:\n",
        "        file = csv.reader(f)\n",
        "        for row in file:\n",
        "            labels_dict[row[0]] = row[1]\n",
        "    return labels_dict\n",
        "\n",
        "\n",
        "def get_predators_dict(file): \n",
        "    all_predators = {}\n",
        "    with open(file, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            all_predators[row[0]] = 1\n",
        "    return all_predators\n",
        "            \n",
        "\n",
        "def get_features_labels(root, labels_dict, all_predators):\n",
        "    corpus = [] # each row is a string formed from all messages in a conversations\n",
        "    labels = [] # each row is 0 or 1, corresponds to label for same row in corpus\n",
        "\n",
        "    for conversation in root:\n",
        "        # only get suspicious conversations\n",
        "        if labels_dict[conversation.get('id')] == '0':\n",
        "            continue\n",
        "        author_conv_dict = {}\n",
        "        for message in conversation:\n",
        "            author = message.find('author').text\n",
        "            text = message.find('text').text\n",
        "            if text is not None:\n",
        "                if author not in author_conv_dict:\n",
        "                    author_conv_dict[author] = text\n",
        "                else:\n",
        "                    author_conv_dict[author] += \" \" + text \n",
        "        for author, conv in author_conv_dict.items():\n",
        "            corpus.append(conv)\n",
        "            if author in all_predators:\n",
        "                labels.append(1)\n",
        "            else:\n",
        "                labels.append(-1)\n",
        "    return corpus, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cYHIdElyR35"
      },
      "source": [
        "train_data_path = '/content/drive/MyDrive/online-grooming-detector-master/data/svm_training_data/'\n",
        "training_xml = ET.parse(train_data_path + 'training_data.xml')\n",
        "train_root = training_xml.getroot()\n",
        "\n",
        "test_data_path = '/content/drive/MyDrive/online-grooming-detector-master/data/svm_test_data/'\n",
        "test_data_src = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-test-corpus-2012-05-21/'\n",
        "test_xml = ET.parse(test_data_src + 'pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
        "test_root = test_xml.getroot()\n",
        "\n",
        "pred_train_file_path = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt'\n",
        "pred_test_file_path = '/content/drive/MyDrive/online-grooming-detector-master/data/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem1.txt'\n",
        "train_corpus, train_labels = get_features_labels(train_root, get_susp_conv_dict(train_data_path), get_predators_dict(pred_train_file_path))\n",
        "test_corpus, test_labels = get_features_labels(test_root, get_susp_conv_dict(test_data_path), get_predators_dict(pred_test_file_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSE1BJ15yWR6"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy\n",
        "# from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# print(train_corpus[:5])\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "# vectorizer = TfidfVectorizer(analyzer='word')\n",
        "X_train = vectorizer.fit_transform(train_corpus)\n",
        "X_test = vectorizer.transform(test_corpus)\n",
        "\n",
        "print(\"Training data shape: {}\".format(X_train.shape))\n",
        "print(\"Testing data shape: {}\".format(X_test.shape))\n",
        "\n",
        "X_train = scipy.sparse.csr_matrix(X_train)\n",
        "y_train = np.array(train_labels)\n",
        "X_test = scipy.sparse.csr_matrix(X_test)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "print(\"Training data shape: {}\".format(X_train.shape))\n",
        "print(\"Testing data shape: {}\".format(X_test.shape))\n",
        "print(\"Training label shape: {}\".format(y_train.shape))\n",
        "print(\"Testing label shape: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZuVkOfWyZmh"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import heapq\n",
        "import operator\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "num_fold = 10\n",
        "k_fold = KFold(num_fold, True, 1)\n",
        "acc = []\n",
        "\n",
        "for coef_c in np.arange(0.1, 5.1, 0.1):#return evenly spaced values within the given arrangement start 0.1 stop 5.1 step 0.1\n",
        "    acc_arr = np.zeros(num_fold)#return a new array of specified size and shape containing only zeros\n",
        "    ind = 0# !!!!!!check if count!!!!!!!!\n",
        "    for train_rows, val_rows in k_fold.split(X_train):#Generate indices to split data into training and test set.\n",
        "#         model = svm.SVC(kernel=kernel, C=coef_c, gamma='auto', random_state=0)\n",
        "        model = LinearSVC(random_state=0, C=coef_c, loss='squared_hinge', dual=True)\n",
        "        model.fit(X_train[train_rows], y_train[train_rows])\n",
        "        pred_y = model.predict(X_train[val_rows])\n",
        "        acc_arr[ind] = metrics.accuracy_score(y_train[val_rows], pred_y)\n",
        "        ind += 1\n",
        "    acc.append([coef_c, np.mean(acc_arr)])\n",
        "plt.plot([i[0] for i in acc], [i[1] for i in acc])\n",
        "plt.title(\"Performance of LINEAR SVM\")\n",
        "plt.xlabel(\"C valve\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "best = heapq.nlargest(1, acc, key=operator.itemgetter(1))[0]\n",
        "print(\"Best performing linear kernel SVM: C={}, Acc={}\".format(best[0], best[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzxps2mMyd9I"
      },
      "source": [
        "# model = svm.SVC(kernel='linear', C=best[0], gamma='auto', random_state=0)\n",
        "#model = LinearSVC(random_state=0, tol=1e-5, loss='squared_hinge')\n",
        "model = LinearSVC(random_state=0, C=best[0], loss='squared_hinge')\n",
        "model.fit(X_train, y_train)\n",
        "pred_y = model.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, pred_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Np5OoI2ygvN"
      },
      "source": [
        "import pickle\n",
        "import datetime\n",
        "\n",
        "# save the model to the models folder\n",
        "filename = '/content/drive/MyDrive/online-grooming-detector-master/models/VFP_SVM_' + \"{:.2f}_\".format(metrics.accuracy_score(y_test, pred_y)) + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}